{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported - ready to use PyTorch 1.12.1+cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy import constants\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.callbacks\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras\n",
    "from keras.layers import  Input, Flatten, Dense, Lambda, Reshape\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as td\n",
    "\n",
    "# Set random seed for reproducability\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_h_lhs=pd.read_csv('h_LHS.csv',index_col=False)\n",
    "data_h_T_lhs=pd.read_csv('h_T_LHS.csv',index_col=False)\n",
    "data_lambda_lhs=pd.read_csv('lambda_LHS.csv',index_col=False)\n",
    "data_T_lhs=pd.read_csv('T_LHS.csv',index_col=False)\n",
    "\n",
    "data_h_uniform_5000=pd.read_csv('h_uniform_5000.csv',index_col=False)\n",
    "data_T_uniform_5000=pd.read_csv('T_uniform_5000.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_h_T_lhs.values## Input to first NN(h,T)\n",
    "Y=data_lambda_lhs.values ## Output of first NN(Lambda) for MSE\n",
    "\n",
    "# Scaling for only inputs\n",
    "min_max_scaler =MinMaxScaler()\n",
    "\n",
    "X_scale= min_max_scaler.fit_transform(X)\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3) ## Train and validation set(Train=3500 Validation=1500)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)  ## validation and test set(Validatioin=750 Test=750)\n",
    "\n",
    "X_h=data_h_lhs.values## Input to Second NN(h) along with output from NN\n",
    "Y_T=data_T_lhs.values ## Output for second NN(T) for MSE\n",
    "h_scale=min_max_scaler.fit_transform(X_h)\n",
    "T_scale=min_max_scaler.fit_transform(Y_T)\n",
    "h_train, h_val_and_test, Y_T_train, Y_T_val_and_test = train_test_split(h_scale, T_scale, test_size=0.3) ## Train and validation set(Train=3500 Validation=1500)\n",
    "h_val, h_test, Y_T_val, Y_T_test = train_test_split(h_val_and_test, Y_T_val_and_test, test_size=0.5)  ## validation and test set(Validatioin=750 Test=750)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                192       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " class (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,305\n",
      "Trainable params: 2,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, input_dim=2, activation='relu'))  ##input layer with two input as (h,T)\n",
    "model.add(layers.Dense(32, activation='relu'))   ## Hidden layer\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(1, activation='linear', name='class'))\n",
    "# model.add(layers.Dense(64, input_dim=2, activation='relu'))  ##input layer with two input as (h,T)\n",
    "# model.add(layers.Dense(32, activation='relu'))   ## Hidden layer\n",
    "# model.add(layers.Dropout(0.1))\n",
    "# model.add(layers.Dense(1, activation='linear', name='class_Secind NN'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3500 samples\n",
      "Epoch 1/20\n",
      "3500/3500 [==============================] - 1s 188us/sample - loss: 2.9044e-07\n",
      "Epoch 2/20\n",
      "3500/3500 [==============================] - 0s 54us/sample - loss: 2.5255e-07\n",
      "Epoch 3/20\n",
      "3500/3500 [==============================] - 0s 53us/sample - loss: 2.4971e-07\n",
      "Epoch 4/20\n",
      "3500/3500 [==============================] - 0s 50us/sample - loss: 2.5307e-07\n",
      "Epoch 5/20\n",
      "3500/3500 [==============================] - 0s 52us/sample - loss: 2.5054e-07\n",
      "Epoch 6/20\n",
      "3500/3500 [==============================] - 0s 50us/sample - loss: 2.5383e-07\n",
      "Epoch 7/20\n",
      "3500/3500 [==============================] - 0s 47us/sample - loss: 2.5086e-07\n",
      "Epoch 8/20\n",
      "3500/3500 [==============================] - 0s 47us/sample - loss: 2.5375e-07\n",
      "Epoch 9/20\n",
      "3500/3500 [==============================] - 0s 58us/sample - loss: 2.4976e-07\n",
      "Epoch 10/20\n",
      "3500/3500 [==============================] - 0s 42us/sample - loss: 2.5292e-07\n",
      "Epoch 11/20\n",
      "3500/3500 [==============================] - 0s 44us/sample - loss: 2.5288e-07\n",
      "Epoch 12/20\n",
      "3500/3500 [==============================] - 0s 52us/sample - loss: 2.5096e-07\n",
      "Epoch 13/20\n",
      "3500/3500 [==============================] - 0s 49us/sample - loss: 2.5353e-07\n",
      "Epoch 14/20\n",
      "3500/3500 [==============================] - 0s 50us/sample - loss: 2.5189e-07\n",
      "Epoch 15/20\n",
      "3500/3500 [==============================] - 0s 51us/sample - loss: 2.5230e-07\n",
      "Epoch 16/20\n",
      "3500/3500 [==============================] - 0s 48us/sample - loss: 2.5220e-07\n",
      "Epoch 17/20\n",
      "3500/3500 [==============================] - 0s 49us/sample - loss: 2.5134e-07\n",
      "Epoch 18/20\n",
      "3500/3500 [==============================] - 0s 47us/sample - loss: 2.5097e-07\n",
      "Epoch 19/20\n",
      "3500/3500 [==============================] - 0s 46us/sample - loss: 2.5087e-07\n",
      "Epoch 20/20\n",
      "3500/3500 [==============================] - 0s 47us/sample - loss: 2.5553e-07\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mse')\n",
    "NN_lambda=model.fit(X_train, Y_train, epochs=20)\n",
    "input_nn2=[NN_lambda,h_train]\n",
    "NN_T=model.fit(input_nn2,Y_T_train)\n",
    "out_T=NN_T\n",
    "losses=loss(NN_lambda,Y_train,Y_T_train,out_T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading values only\n",
    "h_in=data_h_lhs.values\n",
    "T_in=data_T_lhs.values\n",
    "Lambda_in=data_lambda_lhs.values\n",
    "\n",
    "# Scaling the input and outputs\n",
    "min_max_scaler =MinMaxScaler()\n",
    "h_scale_in= min_max_scaler.fit_transform(h_in)\n",
    "T_scale_in= min_max_scaler.fit_transform(T_in)\n",
    "Lambda_scale_in= min_max_scaler.fit_transform(Lambda_in)\n",
    "\n",
    "## Converting into tensor for nn\n",
    "h_tensor=torch.Tensor(h_scale_in)\n",
    "T_tensor=torch.Tensor(T_scale_in)\n",
    "Lambda_tensor=torch.Tensor(Lambda_scale_in)\n",
    "\n",
    "\n",
    "##test Data preparation\n",
    "h_test_in_5000=data_h_uniform_5000.values\n",
    "T_test_in_5000=data_T_uniform_5000.values\n",
    "\n",
    "scale_h_test_in_5000=min_max_scaler.fit_transform(h_test_in_5000)\n",
    "scale_T_test_in_5000=min_max_scaler.fit_transform(T_test_in_5000)\n",
    "\n",
    "\n",
    "h_tensor_5000=torch.Tensor(scale_h_test_in_5000)\n",
    "T_tensor_5000=torch.Tensor(scale_T_test_in_5000)\n",
    "\n",
    "\n",
    "# zipped_tensor=zip(h_tensor,T_tensor,Lambda_tensor)\n",
    "# tuple = (h_tensor, T_tensor)\n",
    "# new_tensor = torch.cat(tuple,-1)\n",
    "# T = torch.stack((h_tensor,T_tensor), -1)  ## this one is working\n",
    "# new_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (fc4): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (fc5): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (fc6): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.fc4 = nn.Linear(2, 32)\n",
    "        self.fc5 = nn.Linear(32, 64)\n",
    "        self.fc6 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, h,T):\n",
    "        \n",
    "        tuple_in1 = (h_tensor, T_tensor)\n",
    "        in_1 = torch.cat(tuple_in1,-1)\n",
    "        # in_1 = torch.stack(h,T)\n",
    "        # in_1=torch.concat(h,T)\n",
    "        x1 = torch.relu(self.fc1(in_1))\n",
    "        x2 = torch.relu(self.fc2(x1))\n",
    "        output_1 = self.fc3(x2)\n",
    "\n",
    "        tuple_in2 = (output_1, T_tensor)\n",
    "        in_2 = torch.cat(tuple_in2,-1)\n",
    "        # in_2 = torch.stack(output_1,h)\n",
    "        # in_2=torch.concat(output_1,h)\n",
    "        x3 = torch.relu(self.fc4(in_2))\n",
    "        x4 = torch.relu(self.fc5(x3))\n",
    "        output_2 = self.fc6(x4)\n",
    "        return output_1,output_2\n",
    "\n",
    "# Create a model instance from the network\n",
    "model = Net()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_criteria=nn.MSELoss()\n",
    "def train(model,h,T,lam,optimizer):\n",
    "  for i in range(len(h)):\n",
    "    model.train()\n",
    "    \n",
    "    # for i in range(len(h)):\n",
    "    # optimizer.zero_grad()\n",
    "    out1,out2=model(h[i],T[i])\n",
    "    loss1=loss_criteria(out1[i],lam[i])\n",
    "    loss2=loss_criteria(out2[i],T[i])\n",
    "    loss=loss1+loss2\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  return loss,out1,out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n",
      "Epoch: 4\n",
      "Epoch: 5\n",
      "Epoch: 6\n",
      "Epoch: 7\n",
      "Epoch: 8\n",
      "Epoch: 9\n",
      "Epoch: 10\n",
      "Epoch: 11\n",
      "Epoch: 12\n",
      "Epoch: 13\n",
      "Epoch: 14\n",
      "Epoch: 15\n",
      "Epoch: 16\n",
      "Epoch: 17\n",
      "Epoch: 18\n",
      "Epoch: 19\n",
      "Epoch: 20\n",
      "Epoch: 21\n",
      "Epoch: 22\n",
      "Epoch: 23\n",
      "Epoch: 24\n",
      "Epoch: 25\n",
      "Epoch: 26\n",
      "Epoch: 27\n",
      "Epoch: 28\n",
      "Epoch: 29\n",
      "Epoch: 30\n",
      "Epoch: 31\n",
      "Epoch: 32\n",
      "Epoch: 33\n",
      "Epoch: 34\n",
      "Epoch: 35\n",
      "Epoch: 36\n",
      "Epoch: 37\n",
      "Epoch: 38\n",
      "Epoch: 39\n",
      "Epoch: 40\n",
      "Epoch: 41\n",
      "Epoch: 42\n",
      "Epoch: 43\n",
      "Epoch: 44\n",
      "Epoch: 45\n",
      "Epoch: 46\n",
      "Epoch: 47\n",
      "Epoch: 48\n",
      "Epoch: 49\n",
      "Epoch: 50\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# We'll track metrics for each epoch in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "# validation_loss = []\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    # print the epoch number\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    \n",
    "    # Feed training data into the model to optimize the weights\n",
    "    train_loss = train(model,h_tensor,T_tensor,Lambda_tensor , optimizer)\n",
    "    \n",
    "    # Log the metrics for this epoch\n",
    "    epoch_nums.append(epoch)\n",
    "    training_loss.append(train_loss)\n",
    "    # validation_loss.append(test_loss)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_5000=model(h_tensor_5000,T_tensor_5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0230],\n",
       "         [0.2972],\n",
       "         [0.7689],\n",
       "         ...,\n",
       "         [0.3062],\n",
       "         [0.6976],\n",
       "         [0.0613]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[1.0002],\n",
       "         [1.0001],\n",
       "         [1.0005],\n",
       "         ...,\n",
       "         [1.0000],\n",
       "         [1.0004],\n",
       "         [1.0000]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_5000[1],prediction_5000[0]  ## outputs from NN as T(out2) and lambda(out1) respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_scaled_lambda_5000=min_max_scaler.inverse_transform(prediction_5000[0].detach().numpy())\n",
    "inverse_scaled_T_5000=min_max_scaler.inverse_transform(prediction_5000[1].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7642.269 ],\n",
       "       [ 5546.808 ],\n",
       "       [23554.324 ],\n",
       "       ...,\n",
       "       [ 1047.7305],\n",
       "       [17929.078 ],\n",
       "       [  750.7801]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_scaled_lambda_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inverse_scaled_lambda_5000' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\Gate 2021\\Applied\\College\\IITD\\APPLIED MECHANICS\\FINAL PROJECT MAGNETOSTRICTIVE\\codes\\Final Data\\LHS_NN.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/Gate%202021/Applied/College/IITD/APPLIED%20MECHANICS/FINAL%20PROJECT%20MAGNETOSTRICTIVE/codes/Final%20Data/LHS_NN.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m inverse_scaled_lambda_5000\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inverse_scaled_lambda_5000' is not defined"
     ]
    }
   ],
   "source": [
    "inverse_scaled_lambda_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-47000000.        ],\n",
       "       [-46525253.70754302],\n",
       "       [-46050507.41508603],\n",
       "       ...,\n",
       "       [  -949254.98962402],\n",
       "       [  -474627.49481201],\n",
       "       [        0.        ]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_inverse_scaled=min_max_scaler.inverse_transform(h_tensor_5000)\n",
    "h_inverse_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x15e100394e0>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(h_inverse_scaled[0:100]/1000,inverse_scaled_lambda_5000[0:100]/10**(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(h_inverse_scaled[0:100]/1000,inverse_scaled_lambda_5000[0:100]/10**(6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be0c76a15e7db832c1cef9e000d0973fde535108692ea45e0855d7f2c98f1a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
