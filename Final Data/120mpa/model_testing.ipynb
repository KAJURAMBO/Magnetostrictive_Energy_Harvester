{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported - ready to use PyTorch 1.12.1+cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "from scipy import stats\n",
    "from scipy import constants\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import ReLU\n",
    "import torch.utils.data as td\n",
    "\n",
    "# Set random seed for reproducability\n",
    "torch.manual_seed(0)\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inverse(nn.Module):\n",
    "        def __init__(self):\n",
    "                super(Inverse, self).__init__()        \n",
    "                self.LAMBDA = nn.Sequential(\n",
    "                        nn.Linear(2, 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 1))\n",
    "\n",
    "                self.stress = nn.Sequential(\n",
    "                        nn.Linear(2, 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, 64),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64, 1))\n",
    "                        \n",
    "                \n",
    "        def forward(self,h,T):\n",
    "                in_1=torch.concat((h,T),1)\n",
    "                lam = self.LAMBDA(in_1) \n",
    "                in_2=torch.concat((lam,h),1) \n",
    "                T   = self.stress(in_2)  \n",
    "\n",
    "                return lam,T          \n",
    "model=Inverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_criteria=nn.MSELoss()\n",
    "## Trainning function definition\n",
    "alpha=1\n",
    "beta=1\n",
    "def train(model,h,T,lam,optimizer):\n",
    "  for i in range(len(h)):\n",
    "    model.train()\n",
    "    \n",
    "    # for i in range(len(h)):\n",
    "    # optimizer.zero_grad()\n",
    "    out1,out2=model(h,T)\n",
    "    loss1=loss_criteria(out1,lam)\n",
    "    loss2=loss_criteria(out2,T)\n",
    "    loss=alpha*loss1+beta*loss2\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  return loss,out1,out2\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Saving the model state of 50 epoch\n",
    "\n",
    "# Additional information\n",
    "EPOCH = 50\n",
    "PATH = \"model_str.pt\"\n",
    "LOSS = 0.015409946\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading model with 100 epoch\n",
    "\n",
    "model = Inverse()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be0c76a15e7db832c1cef9e000d0973fde535108692ea45e0855d7f2c98f1a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
